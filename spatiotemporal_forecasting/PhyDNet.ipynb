{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical Dynamics Neural Network\n",
    "### Overview\n",
    "Physical Dynamics Neural Network (PhyDNet) is a neural network architecture for spatiotemporal forecasting. It utilises traditional ConvLSTM cells along with a new Physical Dynamics Cell that models differential equations in latent variable space. This allows for the underlying physics of a problem to be modelled.\n",
    "\n",
    "### Dependencies\n",
    "PyTorch 1.5.0 with CUDA 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import random\n",
    "import time\n",
    "\n",
    "from PhyDNet.models import ConvLSTM, PhyCell, EncoderRNN\n",
    "from PhyDNet.constrain_moments import K2M\n",
    "\n",
    "from dataset_utils import GenericDataset, SpatiotemporalDataset\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000\n",
    "N_CHANNELS = 1\n",
    "IM_HEIGHT = 64\n",
    "IM_WIDTH = 64\n",
    "FORECAST_HORIZON = 10\n",
    "LAGS = 10\n",
    "MNIST = False\n",
    "\n",
    "if MNIST:\n",
    "    \n",
    "    X = np.load(\"data/mnist_test_seq.npy\").swapaxes(0,1)\n",
    "    X = np.expand_dims(X, 2)\n",
    "    trainDataset = GenericDataset(X[0:700], FORECAST_HORIZON, LAGS)\n",
    "    validDataset = GenericDataset(X[700:], FORECAST_HORIZON, LAGS)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    X = np.random.normal(0, 1, (N_SAMPLES, N_CHANNELS, IM_HEIGHT, IM_WIDTH)).astype(np.float32)\n",
    "    trainDataset = SpatiotemporalDataset(X, FORECAST_HORIZON, LAGS)\n",
    "    validDataset = SpatiotemporalDataset(X, FORECAST_HORIZON, LAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TRAIN\n",
      "layer  0 input dim  64  hidden dim  128\n",
      "layer  1 input dim  128  hidden dim  128\n",
      "layer  2 input dim  128  hidden dim  64\n",
      "phycell  230833\n",
      "convlstm  2508032\n",
      "encoder  2951002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a88343b05e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder '\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[0mplot_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a88343b05e7a>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, n_epochs, print_every, eval_every)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mloss_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a88343b05e7a>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(input_tensor, target_tensor, encoder, encoder_optimizer, criterion, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mm\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# constrains is a precomputed matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\greg\\desktop\\standard_env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\greg\\desktop\\standard_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root = '/dds/work/PrevisionsPV/codes/video_prediction/SBNet-for-video-prediction/dataset'\n",
    "batch_size = 1\n",
    "n_epochs = 1001\n",
    "print_every = 1\n",
    "eval_every = 5\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainDataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=validDataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "constraints = torch.zeros((49,7,7)).to(device)\n",
    "ind = 0\n",
    "for i in range(0,7):\n",
    "    for j in range(0,7):\n",
    "        constraints[ind,i,j] = 1\n",
    "        ind +=1    \n",
    "\n",
    "    \n",
    "def train_on_batch(input_tensor, target_tensor, encoder, encoder_optimizer, criterion,teacher_forcing_ratio):                \n",
    "    encoder_optimizer.zero_grad()\n",
    "    # input_tensor : torch.Size([batch_size, input_length, 1, 64, 64])\n",
    "    input_length  = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "    loss = 0\n",
    "    for ei in range(input_length-1): \n",
    "        encoder_output, encoder_hidden, output_image,_,_ = encoder(input_tensor[:,ei,:,:,:], (ei==0) )\n",
    "        loss += criterion(output_image,input_tensor[:,ei+1,:,:,:])\n",
    "\n",
    "    decoder_input = input_tensor[:,-1,:,:,:] # first decoder input = last image of input sequence\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input)\n",
    "            target = target_tensor[:,di,:,:,:]\n",
    "            loss += criterion(output_image,target)\n",
    "            decoder_input = target \n",
    "         \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input)\n",
    "            decoder_input = output_image\n",
    "            target = target_tensor[:,di,:,:,:]\n",
    "            loss += criterion(output_image, target)\n",
    " \n",
    "    # Moment Regularisation  encoder.phycell.cell_list[0].F.conv1.weight # size (nb_filters,in_channels,7,7)\n",
    "    k2m = K2M([7,7]).to(device)\n",
    "    for b in range(0,encoder.phycell.cell_list[0].input_dim):\n",
    "        filters = encoder.phycell.cell_list[0].F.conv1.weight[:,b,:,:] # (nb_filters,7,7)\n",
    "        \n",
    "        m = k2m(filters.double()) \n",
    "        m  = m.float()   \n",
    "        loss += criterion(m, constraints) # constrains is a precomputed matrix   \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "def trainIters(encoder, n_epochs, print_every,eval_every):\n",
    "    start = time.time()\n",
    "    train_losses = []\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(),lr=0.0001)\n",
    "    scheduler_enc = ReduceLROnPlateau(encoder_optimizer, mode='min', patience=3,factor=0.5,verbose=True)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(0, n_epochs ):\n",
    "        t0 = time.time()\n",
    "        loss_epoch = 0\n",
    "        teacher_forcing_ratio = np.maximum(0 , 1 - epoch * 0.01)\n",
    "        \n",
    "        for i, (idx, input_tensor, target_tensor) in enumerate(train_loader, 0):\n",
    "            #input_batch =  torch.Size([8, 20, 1, 64, 64])\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "            loss = train_on_batch(input_tensor, target_tensor, encoder, encoder_optimizer, criterion, teacher_forcing_ratio)                                   \n",
    "            loss_epoch += loss\n",
    "            \n",
    "        if (i%10)==0 :\n",
    "            print(i, '/', len(train_loader) , ' loss= ' , loss)\n",
    "            \n",
    "        train_losses.append(loss_epoch)        \n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print('epoch ',epoch,  ' loss ',loss_epoch , ' epoch time ',time.time()-t0)\n",
    "            \n",
    "        if (epoch+1) % eval_every == 0:\n",
    "            mse, mae,ssim = evaluate(encoder,test_loader) \n",
    "            scheduler_enc.step(mse)                              \n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def evaluate(encoder,loader):\n",
    "    total_mse, total_mae,total_ssim,total_bce = 0,0,0,0\n",
    "    with torch.no_grad():\n",
    "        for i, (idx, input_tensor, target_tensor) in enumerate(loader, 0):\n",
    "            #input_batch = torch.Size([8, 20, 1, 64, 64])\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "\n",
    "            input_length = input_tensor.size()[1]\n",
    "            target_length = target_tensor.size()[1]\n",
    "\n",
    "            for ei in range(input_length-1):\n",
    "                encoder_output, encoder_hidden, _,_,_  = encoder(input_tensor[:,ei,:,:,:], (ei==0))\n",
    "\n",
    "            decoder_input = input_tensor[:,-1,:,:,:] # first decoder input= last image of input sequence\n",
    "            predictions = []\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, output_image,_,_ = encoder(decoder_input, False, False)\n",
    "                decoder_input = output_image\n",
    "                predictions.append(output_image.cpu())\n",
    "\n",
    "            input = input_tensor.cpu().numpy()\n",
    "            target = target_tensor.cpu().numpy()\n",
    "            predictions =  np.stack(predictions) # for MM: (10, batch_size, 1, 64, 64)\n",
    "            predictions = predictions.swapaxes(0,1)  # (batch_size,10, 1, 64, 64)\n",
    "\n",
    "            mse_batch = np.mean((predictions-target)**2 , axis=(0,1,2)).sum()\n",
    "            mae_batch = np.mean(np.abs(predictions-target) ,  axis=(0,1,2)).sum() \n",
    "            total_mse += mse_batch\n",
    "            total_mae += mae_batch\n",
    "            \n",
    "            for a in range(0,target.shape[0]):\n",
    "                for b in range(0,target.shape[1]):\n",
    "                    total_ssim += ssim(target[a,b,0,], predictions[a,b,0,]) / (target.shape[0]*target.shape[1]) \n",
    "            \n",
    "            cross_entropy = -target*np.log(predictions) - (1-target) * np.log(1-predictions)\n",
    "            cross_entropy = cross_entropy.sum()\n",
    "            cross_entropy = cross_entropy / (batch_size*target_length)\n",
    "            total_bce +=  cross_entropy\n",
    "     \n",
    "    print('eval mse ', total_mse/len(loader),  ' eval mae ', total_mae/len(loader),' eval ssim ',total_ssim/len(loader), ' eval bce ', total_bce/len(loader))        \n",
    "    return total_mse/len(loader),  total_mae/len(loader), total_ssim/len(loader)\n",
    "\n",
    "\n",
    "\n",
    "print('BEGIN TRAIN')\n",
    "phycell =  PhyCell(input_shape=(16,16), input_dim=64, F_hidden_dims=[49], n_layers=1, kernel_size=(7,7), device=device) \n",
    "convlstm =  ConvLSTM(input_shape=(16,16), input_dim=64, hidden_dims=[128,128,64], n_layers=3, kernel_size=(3,3), device=device)   \n",
    "encoder = EncoderRNN(phycell, convlstm, device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "   \n",
    "print('phycell ' , count_parameters(phycell) )    \n",
    "print('convlstm ' , count_parameters(convlstm) ) \n",
    "print('encoder ' , count_parameters(encoder) ) \n",
    "\n",
    "plot_losses = trainIters(encoder,n_epochs,print_every=print_every,eval_every=eval_every)\n",
    "print(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
