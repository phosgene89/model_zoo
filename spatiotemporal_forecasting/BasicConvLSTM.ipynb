{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ConvLSTM\n",
    "### Overview\n",
    "Basic introduction to the ConvLSTM layer implemented by <a href=\"https://github.com/ndrplz\">nrdplz</a> from <a href=\"https://github.com/ndrplz/ConvLSTM_pytorch\">this</a> repository.\n",
    "\n",
    "### Dependencies\n",
    "PyTorch 1.5.0 with CUDA 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from BasicConvLSTM.convlstm import *\n",
    "from earlystopping import EarlyStopping\n",
    "from dataset_utils import GenericDataset, SpatiotemporalDataset\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage of ConvLSTM Layer\n",
    "Parameters:\n",
    "\n",
    "        input_dim: Number of channels in input\n",
    "        \n",
    "        hidden_dim: Number of hidden channels\n",
    "        \n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        \n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        \n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        \n",
    "        bias: Bias or no bias in Convolution\n",
    "        \n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        \n",
    "        Note: Will do same padding.\n",
    "\n",
    "    Input:\n",
    "    \n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "        \n",
    "    Output:\n",
    "    \n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "        \n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            \n",
    "            1 - last_state_list is the list of last states\n",
    "            \n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "                    \n",
    "    Example:\n",
    "    \n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        \n",
    "        >> convlstm = ConvLSTM(64, 16, (3, 3), 1, True, True, False)\n",
    "        \n",
    "        >> _, last_states = convlstm(x)\n",
    "        \n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of layer output list: 3\n",
      "Length of last state list: 3\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 10, 3, 32, 32))\n",
    "convlstm = ConvLSTM(3, [16, 16, 16], (3, 3), 3, True, True, True)\n",
    "layer_output_list, last_state_list = convlstm(x)\n",
    "\n",
    "print(\"Length of layer output list: {}\".format(len(layer_output_list)))\n",
    "print(\"Length of last state list: {}\".format(len(last_state_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Moving MNIST with Basic ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10000\n",
    "N_CHANNELS = 1\n",
    "IM_HEIGHT = 64\n",
    "IM_WIDTH = 64\n",
    "FORECAST_HORIZON = 10\n",
    "LAGS = 10\n",
    "MNIST = True\n",
    "\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "frames_input = 10\n",
    "frames_output = 10\n",
    "epochs = 500\n",
    "\n",
    "TIMESTAMP = str(datetime.now())\n",
    "\n",
    "save_dir = './save_model/' + TIMESTAMP\n",
    "\n",
    "if MNIST:\n",
    "    \n",
    "    X = np.load(\"data/mnist_test_seq.npy\").swapaxes(0,1)\n",
    "    X = np.expand_dims(X, 2)\n",
    "    trainDataset = GenericDataset(X[0:700], FORECAST_HORIZON, LAGS)\n",
    "    validDataset = GenericDataset(X[700:], FORECAST_HORIZON, LAGS)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    X = np.random.normal(0, 1, (N_SAMPLES, N_CHANNELS, IM_HEIGHT, IM_WIDTH))\n",
    "    trainDataset = SpatiotemporalDataset(X, FORECAST_HORIZON, LAGS)\n",
    "    validDataset = SpatiotemporalDataset(X, FORECAST_HORIZON, LAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(trainDataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "validLoader = torch.utils.data.DataLoader(validDataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm = ConvLSTM(1, [32, 1], (3, 3), 2, True, True, True)\n",
    "\n",
    "layer_output_list, last_state_list = convlstm(torch.Tensor(inputs).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, device):\n",
    "    '''\n",
    "    main function to run the training\n",
    "    '''\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    cur_epoch = 0\n",
    "    lossfunction = nn.MSELoss().cuda()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    pla_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      factor=0.5,\n",
    "                                                      patience=4,\n",
    "                                                      verbose=True)\n",
    "\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = []\n",
    "    # mini_val_loss = np.inf\n",
    "    for epoch in range(cur_epoch, epochs + 1):\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        t = tqdm(trainLoader, leave=False, total=len(trainLoader))\n",
    "        for i, (idx, targetVar, inputVar) in enumerate(t):\n",
    "            inputs = inputVar.to(device).float()  # B,S,C,H,W\n",
    "            label = targetVar.to(device).float()  # B,S,C,H,W\n",
    "            optimizer.zero_grad()\n",
    "            net.train()\n",
    "            pred, _ = net(inputs)  # B,S,C,H,W\n",
    "            pred = pred[-1]\n",
    "            loss = lossfunction(pred, label)\n",
    "            loss_aver = loss.item() / batch_size\n",
    "            train_losses.append(loss_aver)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(net.parameters(), clip_value=10.0)\n",
    "            optimizer.step()\n",
    "            t.set_postfix({\n",
    "                'trainloss': '{:.6f}'.format(loss_aver),\n",
    "                'epoch': '{:02d}'.format(epoch)\n",
    "            })\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            t = tqdm(validLoader, leave=False, total=len(validLoader))\n",
    "            for i, (idx, targetVar, inputVar) in enumerate(t):\n",
    "                if i == 3000:\n",
    "                    break\n",
    "                inputs = inputVar.to(device).float()\n",
    "                label = targetVar.to(device).float()\n",
    "                pred, _ = net(inputs)\n",
    "                pred = pred[-1]\n",
    "                loss = lossfunction(pred, label)\n",
    "                loss_aver = loss.item() / batch_size\n",
    "                # record validation loss\n",
    "                valid_losses.append(loss_aver)\n",
    "                #print (\"validloss: {:.6f},  epoch : {:02d}\".format(loss_aver,epoch),end = '\\r', flush=True)\n",
    "                t.set_postfix({\n",
    "                    'validloss': '{:.6f}'.format(loss_aver),\n",
    "                    'epoch': '{:02d}'.format(epoch)\n",
    "                })\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        # print training/validation statistics\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(epochs))\n",
    "\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.6f} ' +\n",
    "                     f'valid_loss: {valid_loss:.6f}')\n",
    "\n",
    "        print(print_msg)\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        pla_lr_scheduler.step(valid_loss)  # lr_scheduler\n",
    "        model_dict = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "    with open(\"avg_train_losses.txt\", 'wt') as f:\n",
    "        for i in avg_train_losses:\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(\"avg_valid_losses.txt\", 'wt') as f:\n",
    "        for i in avg_valid_losses:\n",
    "            print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e60230184749de8d0f668db16b1620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=175.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934c2cd5e1cc4ca38e159d03256aa999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/500] train_loss: 691.252760 valid_loss: 687.202883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32f6e0b1ce642c3b02c01aa708758e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=175.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f216cb10ce4a0bb7f03a4e52895949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(convlstm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
